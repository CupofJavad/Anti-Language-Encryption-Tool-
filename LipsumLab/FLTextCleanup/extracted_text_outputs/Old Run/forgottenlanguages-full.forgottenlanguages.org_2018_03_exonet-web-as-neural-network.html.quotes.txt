stigmergy: the unintended collaboration between agents resulting from their actions on a shared environment

the future is turning the super-intelligent web as a “global brain” for humanity. In this scenario
users do not even need to enter keywords or explicitly formulate their queries, as their software agents implicitly learn their interests, while immediately taking into account changes in focus of attention

quantitative stigmergy is able to turn the web from a passive medium for communication and storage of information into an intelligent mediator that uses learning and inference mechanisms similar to those of the human brain to recommend to its users the actions, information sources, or people most likely to be helpful for their aims. Well, that's what we want the user to believe. Actually we will feed the user with whatever information we deem useful for national security

ExoNet allows to train the world wide web turning it into the largest neural network ever. It works with millions of parameters to achieve the best performance on the tasks we are currently interested in, mainly language modeling, image classification, machine translation and signal analysis. The www encodes knowledge as a conditional distribution over outputs given an input. The input is obviously the content we put in the selected web sites and those we call echo chambers, and the output is simply that: a distribution of probabilities of certain parameters which is the result of the interaction of users among each other as a result of their being exposed to the input

User preference determines what specific content they consume but, to be honest, when we refer to pornography the content is always the same: facesitting, blowjobs, cougar fucks young boy, anal sex, etc. Actually, there are just 25 categories to choose from. When we want a specific circuit to be reinforced we inject some thousand web sites with redirecting cookies, or we ourselves generate new specific porn content. Have you ever wondered about the ties between the LA pornography industry and DoD? The answer is ExoNet

ExoNet required the analysis of the the global behavior of the entire population of the Internet users. For this, we modeled the TCP downstream traffic. We then analyzed users’ behavior during each day of the collected traces. The main statistical magnitudes of downloaded TCP traffic for users are obtained that way. You end up with a model of the average user, plus a model of the average path density. Based on those models we train ExoNet. ExoNet simply considers the world network as a multi-agent system, a system in which an emergent statistical structure appears which corresponds to the Internet demand by users, users that can be modeled as probabilistic distributions that describe their behavior
