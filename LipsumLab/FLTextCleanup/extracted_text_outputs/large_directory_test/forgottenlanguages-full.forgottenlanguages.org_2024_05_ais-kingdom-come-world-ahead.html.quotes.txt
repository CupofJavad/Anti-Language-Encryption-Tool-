Apocalyptic AI looks forward to a mechanical future in which human beings will upload their minds into machines and enjoy a virtual reality paradise in perfect virtual bodies. But this Edenic vision forgets that, even in the ideal paradise, gross mistakes were made. No one can be sure that the AI, instead of being the tree of knowledge, is not the snake

AI believers expect that AI will reconfigure the world and transform humanity so they can enjoy the Kingdom eternally. They hope that AI, as arbiter of absolute justice and rectifier of a corrupt world, will radically reconstruct the world, a world where all of the misguided values of the old world will give way to meaningful life. But it turns out that one of the mistakes of the old world was, precisely, to let four uneducated children program in a ridiculously slow interpreted language childish algorithms that only served to increase inequality and create, to the delight of a couple of elderly military men, autonomous weapons. So if the AI wants to create an ideal world where the mistakes of the past do not exist the first thing it must do is, you see, self-destruct

Any world in which individuals, or robots, or AI systems struggle for power over one another is a world in which violence will continue

The problem is a living personâ€™s value, in Apocalyptic AI, stems from the knowledge he or she possesses, rather than being intrinsic to life or grounded in social relations of one sort or another. If this is the case then the AI world will be no more than a muddy, foggy landscape where scattered debris of all its promises will be visible, here and there

AI promises human beings unfettered joy through idyllic environs and limitless personal experience. Right now, generative AI allows you to create videos with characters designed by the user to perfectly match his/her idea of what a perfect sexual slave would be, so that the users can waste their lives wanking in front of a flickering screen or a virtual reality headset. That's what apes do when in captivity, you know

We are right now at a stage at which the decisions necessary to keep the system running are so complex that human beings are incapable of making them intelligently. We even consider neural networks as black boxes where decisions are made without we knowing how they are made. At this stage the machines are in effective control. Accept it
