Computationally speaking it is more efficient for a self-improving superintelligence to eliminate consciousness. In fact, 
consciousness is just a blip, an anomaly, and we have no proof that consciousness represents any evolutive advantage at all. 
I always believed that contact would be between humans and a nonconscious superintelligence, and in this sense 
I do not think object DP-2147 is conscious. But it might well be the case there are different ways of being 
conscious, ways about which we ignore everything. After all, the only example we have of what is consciousness 
is our own realization that we are conscious beings. That's a meager example

The superintelligence might be designed with the goal to learn and then 
instantiate human values; however, after observing humans degrading 
their environment, and setting up sociotechnological schemes which 
spread inequality and injustice, the superintelligence may wrongly infer 
that an essential value for humans is to self-destruct, and it may then 
trigger actions in order to align itself with those values. This would 
translate into the superintelligence taking decisions that lead to the 
destruction of humanity not because it is a malevolent superinteligence, 
but rather because it wrongly infers humans wish to be destroyed

Making good use of highly intelligent machines requires ensuring that 
the objectives of such machines are well aligned with those of humans. 
The problem is that after making a thorough observation of Sol-3 
technosphere it would be extremely difficult for the superintelligence 
to not conclude humans' ultimate goal is to screw their home planet

Once the AI became superintelligent it came to the conclusion that 
humans didn't have anything of value to offer; the superintelligence 
encoded all its knowledge in one single logic: humans are not safe to 
themselves. Humans are doomed because they are trying to align 
superintelligent systems to values of humanity, which is itself 
displaying inherently unsafe behaviors. The maxim garbage in/garbage out 
means whatever intelligent system humans finally design, it will destroy 
them
