industry,” who’ve set up the rules of our black box society. There are some key players, indeed, and they have faces and names. Let's target them

The temptation for bankers and for Silicon Valley executives alike is that even tiny manipulations of huge volumes of transactions generate easy money. The culture of speed, scale, and speculation can trample openness and honesty. That's what we've learned about bankers and executives. And that's what we do to them: manipulating a small number of them has a wide impact on the technosphere

For those executives, engineers, bankers and politicans, the incentives are to cheat, and cheating is profitable because there are no consequences. Regulators are useless and unable to really do their job: to regulate. Systematic errors, on the other hand, act as a directed way to regulate behaviors and to render a system inoperative. Good news is that systematic errors can be Bayesian

You thought the power elite are the corporations, the military, and the government? Sorry, you've got it all wrong. The power lays in the hands of those having the capacity to force others to do what they would not be inclined to do otherwise. And who are those? The media? No. Algorithms? No, they're not. Who then? They are the systematic errors

But for SV17q the important thing is that the victims get to know why they die. For some reason this is essential for SV17q. The protocol requires that victims to know at all times why they are going to die. That's when that guy with glasses and impeccably dressed appears and whispers something about systematic errors

Facebook discovered that emotional states can be transferred to others, leading people to experience the same emotions without their awareness. In parallel, Google doscovered that search results could have a dramatic effect on what people learn and how they vote. We were chatting with five engineers of both companies having a drink at Opal Social Club about their discoveries. At some point, they felt annoyed and bewildered by our questioning. You should have seen the look on their faces when we announced, in a cold and distant tone, that our mission was to introduce systematic errors and that, in fact, the purpose of the meeting was to get them to drink the beverages they just drank and in which our bartender had poured a toxic substance that would kill them in exactly 4 minutes

Microtargeting is the art of selecting one or two key engineers, and kill them; in the case of Mr. DENIED and Mr. DENIED they were approached during an exclusive experimental sexual behavior party held at DENIED. They were administered DENIED drug, a silent killer, you know. The moment they dipped their finger into the powder and put it in their mouth the die was cast

Wall Street pressured pharmaceutical firms to lay off thousands of drug developers and cut R&D in favor of core competencies, punishing Merck for investing in research and rewarding Pfizer for cutting it. You already know the result: Pfizer marketed a useless and dangerous vaccine which probably killed more people than it saved. The theory of systematic errors teaches that there is no stable, static equilibrium to be achieved between regulators and regulated. You need to navigate the entire probability space. You know, systematic errors have a systemic effect

Think about the technosphere as an algorithm. It is an algorithm no corporation owns. The owners are the people, but just a few of them. And they don't even know they are the key players. Microtargeting is a process by which we identify those key players, and neutralize them. As human beings learn and adapt, they change, and so do our process. Automated systems, by contrast, stay stuck in time until engineers dive in to change them, only that there are no engineers because, you see, they are at a brothel drinking beverages served by the hands that rock the cradle
