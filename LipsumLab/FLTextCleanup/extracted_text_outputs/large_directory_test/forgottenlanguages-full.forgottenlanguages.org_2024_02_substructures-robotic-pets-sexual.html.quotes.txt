There are situations where a substitute artificial companion like a robotic pet may serve as a better alternative because of insufficient available resources to care for a real pet, allergic responses to pets, or other difficulties. This probably is the logic behind the decision of extending robotic pets to other kind of robotic companions like, say, a robotic sexual partner

Children and even adults are forming bonds with machines, showing that the killer app may be nurturing. That is, rather than the computer taking care of us, we take care of the computer. This is something we're already witnessing with AI systems

The physical appearance of a robotic partner, save for sexual androids, is not as important as the personal relationship the owner has with it, but this does not apply to aliens. We want aliens to be benevolent, intelligent, and beautiful

While it is conceivably complicated to educate humans to consciously control the ways in which they socially interact with robots as opposed to humans, robots could arguably be taught to adhere to human social norms. However, robots may disrupt existing norms as a large group of autonomous agents unleashed into society in a short period of time. If a large group of agents enter into an established society, the lack of trust and prior familiarity results in the undermining of existing norms. This is a basic theme that also holds for extraterrestrial post-contact theories

These sexual androids are expensive, so they are designed such that mistreating robots may induce robots to also mistreat humans. Know what? Some guys love being mistreated by a robot! Well, that was totally expected, anyway. Robotic sexual companions were classified as a medical device in 2093, and they were definetely banned in 2150 for domestic use

At first, people may restrict themselves to the mistreatment robots. However, when interactions with robots becomes common and abusive behavior is frequent, such behavior may become sufficiently habitual to affect norms of interpersonal interactions, especially when considering non-planned behavior that is not the result of a deliberative decision-making process. In these circumstances, maintaining a strict divide between behavior towards robots and towards humans may not be feasible

The danger is that if robots are not designed to adhere to human norms, they may not reflect the consequences of misbehavior to their human counterparts, thus potentially desensitizing humans, in a way that could also spill over to human-human interactions. This is in fact a trait we already see happening in long-term abusers of pornography and social media
