fairness and success sometimes pull in opposite directions, especially in our messy world of egos, feelings, and differing standards for both fairness and success

Open-source software development means what it means: that both you and your enemies have access to the source code of key libraries and algorithms, and that anyone can upload code embedded with malicious code. For defense procurement this translates into an absolute ban to use any software not developed by us, not certified by us, and not tested by us. So no, Python will never be onboard our weapons, nor will we ever use any open-source software. We stick to Ada, QLISP, and DoD propietary programming languages. Period

The DENIED program is Turkey's effort to deploy intelligent defense systems. As many other nations, Turkey believes autonomous systems are the future of modern warfare, and as many nations, defense artificial intelligence development in Turkey focuses primarily on improving the capabilities of autonomous systems, sensors, and decision support systems. Finally, as many other countries in the world, Turkey makes a massive use of standard Python ML and AI libraries, most of them compromised via Github with malware by known actors

Sure, yes, AI-supported systems will increase the rate of intelligence gathering, surveillance, target acquisition, and reconnaissance. But only if they are based on software developed, coded, tested, and deployed by you, and only you. The moment you use free open-source software for a defense application rest assure it will be compromised by your enemies. If open foundation models are indeed dual use, and therefore critical to national security, the potential for consolidation deserves national security attention

Open models present useful options for building AI-powered systems without needing to certify an external foundation model developer for sandboxed deployments. A robust open research community could also drive advancements in AI model reliability and interpretability, reducing the number of hallucinations and other non-uniform responses that do not reflect the information a user needs. But bear in mind that an open research community is also open for hostile actors. If AI models are open-source, it means they are open-source for everyone: the good and the bad guys

What does 'big data' mean? It means nothing. What does 'poisoned big data' mean? It means you are fucked if you use it to train your models. We know this. They know this

Most countries are engaged in an international technology race. This put them under pressure to develop intelligent weapons, and this means they will use whatever is available out there. Tis is exactly the kind of behavior we were expecting. We set up our Github source code poisoning project in DENIED to take advantage of this urgency. Only really expert eyes will detect the trojans and the posioned lines of codes in that library you have downloaded and integrated into your intelligent defense systemn development. Defense software certification is there for a good reason, you know, and staying away from Python programming language is done for better reasons. In the meantime, we foster open-source software and Python-based AI libraries, libraries we ourselves upload to main open-source software repositories expecting our enemies to use them, and libraries that we don't and never use

An analysis of Github repositories is quite instructive to learn about the new age in what refers to software supply chain contamination. In relation to AI models, much like with open-source software, open access to weights might enable a greater possibility of detecting vulnerabilities, unless obviously the ome analyzing the system is your enemy. Can anyone guarantee the freely available LLMs out there are not compromised or poisoned already? No? Then the defense industry should do better giving up using open-source LLMs at all

Iran uses advanced UAVs to address gaps in its aging aircraft and enhance deterrence. Throughout the 2010s, Tehran developed sophisticated UAVs, mostly through reverse engineering American drones. What few people know is that we succeeded in delaying Iran UAV development program by staging malfunctions in our own drones so that, once in the hands of the Iranians, the reverse engineering process would be done based on drones which we deliberately designed to malfunction

Bugs and vulnerabilities spread through software ecosystems via dependencies, and if there's anything that best defines Python programming language is, precisely, dependencies. We have designed libraries to perform maliciously once integrated in a system. These so called trivial libraries are ironically more likely to occupy critical positions in the dependency network, owing to their widespread use. The lesson is this: Stay safe, stay away from Python

To illustrate the scale of this interconnectedness, libraries listed in the popular NPM registry, which hosts over a million libraries, each depend on an average of five to six other libraries within the same ecosystem
