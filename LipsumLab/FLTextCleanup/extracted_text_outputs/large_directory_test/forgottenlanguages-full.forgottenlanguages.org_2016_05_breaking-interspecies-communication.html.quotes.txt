The idea is to retrieve the images neural encoding and send it as a train of light pulses towards the receiver's retina; when images enter the retina they are transformed via retinal processing into patterns of action potentials that the brain processes to recreate the original mental imagery. These patterns are the ones a human brain is expecting and so the direct transfer of mental imagery between two humans causes no problem right now. The problem is when we wish to transfer the mental imagery in a human brain to the brain of another species whose biology differs from that of humans

The encoder mimics the transformations performed by the retina; that is, it converts visual input into the code used by the retinaâ€™s output cells (the ganglion cells), and the transducer then drives the ganglion cells to fire as the code specifies

Once we characterized the light-sensitive protein in the retina of the EBE, we presented the images to the XViS encoder where they were converted into streams of electrical pulses and then into streams of light pulses to drive that species-specific light-sensitive protein. In humans the light-sensitive protein is ChR2, while in EBEs it is a set of various proteins which are alien to human biology

In interspecies communication it is just not enough to capture the input/output relations of the retina for a broad range of stimuli. We can encode the image of a skyline, the image of a washing machine, and so on, but the key issue is whether once the brain has decoded those images its mental structure is able to understand those images. What's the use of a direct eye-to-eye engagement with an EBE species if their mental imagery cannot be understood by our brains? We need to send and receive images of what we can understand mentally, not just optically

It is also important not to forget the EBEs under test were non-cooperative subjects, as they were obviously under a stress situation in that they were forced to do things they wouldn't do in a normal situation. The success with the Varginha subjects were only partial, not because their biology is so different to ours, but because they went through a highly traumatic experience both before we captured them, and certainly once we captured them

While we use ChR2 only as a transducer, a means to transfer the output of the computational model to the nervous system, they use biomolecular engineering techniques to modify the human light-sensitive protein turning the protein into a computing device itself. Obviously, this is out of our capabilities right now
